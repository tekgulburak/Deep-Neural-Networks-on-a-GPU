{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3fX+0HAxzbq3OEmXwHF2v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tekgulburak/Deep-Neural-Networks-on-a-GPU/blob/main/Training_Deep_Neural_Networks_on_a_GPU_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGjxDSVBq-0m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# Use a white background for matplotlib figures\n",
        "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MNIST(root='data/', download=True, transform=ToTensor())\n"
      ],
      "metadata": {
        "id": "vCB2VVn0wNb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "Fm4F8kIpwXAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[10]"
      ],
      "metadata": {
        "id": "QD0134C1wY2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image,label=dataset[1]\n",
        "print(\"image.shape:\",image.shape)\n",
        "plt.imshow(image.permute(2,1,0),cmap=\"gray\")\n",
        "print(\"label:\",label)"
      ],
      "metadata": {
        "id": "xAJYHhM0wfN5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_size=10000\n",
        "train_size=len(dataset)-val_size\n",
        "train_ds,val_ds=random_split(dataset,[train_size,val_size])\n",
        "len(train_ds),len(val_ds)"
      ],
      "metadata": {
        "id": "pSKeh4qpuSEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=128"
      ],
      "metadata": {
        "id": "D2A-IwRo3iKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=DataLoader(train_ds,batch_size,shuffle=True,num_workers=4,pin_memory=True)\n",
        "val_loader=DataLoader(val_ds,batch_size*2,num_workers=4,pin_memory=True)"
      ],
      "metadata": {
        "id": "6KjBLvbk3tyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images,_ in train_loader:\n",
        "  print(\"images:shape:\",images.shape)\n",
        "  plt.figure(figsize=(16,8))\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(make_grid(images,nrow=16).permute((1,2,0)))\n",
        "  break\n",
        "  "
      ],
      "metadata": {
        "id": "z-G_aGGW5lBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images,labels in train_loader:\n",
        "  print(\"images.shape:\",images.shape)\n",
        "  inputs=images.reshape(-1,784)\n",
        "  print(\"inputs.shape:\",inputs.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "FG9y02ss6IuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs.shape)"
      ],
      "metadata": {
        "id": "wa1lQbRwYthf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=inputs.shape[-1]\n",
        "hidden_size=32"
      ],
      "metadata": {
        "id": "JGAeGhH43MCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer1=nn.Linear(input_size,hidden_size)"
      ],
      "metadata": {
        "id": "tzEuXXl73SRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer1_outputs=layer1(inputs)\n",
        "print(\"layer1 outputs is :\",layer1_outputs.shape)"
      ],
      "metadata": {
        "id": "g7QVkVRb30aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####you can see this evaulation in under cell\n",
        "layer1_outputs_result=inputs@layer1.weight.t() + layer1.bias\n",
        "layer1_outputs_result.shape"
      ],
      "metadata": {
        "id": "nhLrnXLR4MQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(layer1_outputs,layer1_outputs_result)"
      ],
      "metadata": {
        "id": "qqDn4eBY75j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.relu(torch.tensor([[3,-1,0],\n",
        "                     [0.3,-3.5,18]\n",
        "    \n",
        "                     ]))"
      ],
      "metadata": {
        "id": "M4aeRxBT8CdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relu_outputs=F.relu(layer1_outputs)\n",
        "print(\"min(layer1_outputs:\",torch.min(layer1_outputs).item())\n",
        "print(\"min relu outputs:\",torch.min(relu_outputs).item())"
      ],
      "metadata": {
        "id": "BNL0k36U8lMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##bundan sonra 2.layera geçiyoruz.yani ara katmandan çıkış katmanına\n",
        "output_size=10\n",
        "layer2=nn.Linear(hidden_size,output_size)"
      ],
      "metadata": {
        "id": "D_sFSUS99FWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer2_outputs=layer2(relu_outputs)\n",
        "layer2_outputs.shape"
      ],
      "metadata": {
        "id": "GO50papI9ksN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.cross_entropy(layer1_outputs,labels)\n"
      ],
      "metadata": {
        "id": "85mtQ5TW94i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs=(F.relu(inputs@layer1.weight.t()+layer1.bias))@layer2.weight.t()+layer2.bias"
      ],
      "metadata": {
        "id": "_ZIDqgB8PLS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.shape"
      ],
      "metadata": {
        "id": "jcV6koaEPmQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(outputs,layer2_outputs,1e-3)"
      ],
      "metadata": {
        "id": "vMrt57x7Ppda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MnistModel(nn.Module):\n",
        "    \"\"\"Feedfoward neural network with 1 hidden layer\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, out_size):\n",
        "        super().__init__()\n",
        "        # hidden layer\n",
        "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
        "        # output layer\n",
        "        self.linear2 = nn.Linear(hidden_size, out_size)\n",
        "        \n",
        "    def forward(self, a):\n",
        "        # Flatten the image tensors\n",
        "        a = a.view(a.size(0), -1)\n",
        "        # Get intermediate outputs using hidden layer\n",
        "        out = self.linear1(a)\n",
        "        # Apply activation function\n",
        "        out = F.relu(out)\n",
        "        # Get predictions using output layer\n",
        "        out = self.linear2(out)\n",
        "        return out\n",
        "    \n",
        "    \n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "      \n",
        "   \n",
        "  \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
      ],
      "metadata": {
        "id": "m3ryd9yZPyXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "metadata": {
        "id": "9hlrSIQNsBy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size=784\n",
        "hidden_size=32\n",
        "num_classes=10"
      ],
      "metadata": {
        "id": "AnA0qq6ciFZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=MnistModel(input_size,hidden_size=32,out_size=num_classes)"
      ],
      "metadata": {
        "id": "L_OFPeesqZub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for t in model.parameters():\n",
        "  print(t.shape)\n",
        "  "
      ],
      "metadata": {
        "id": "F4XYVIbMqvTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images,labels in train_loader:\n",
        "  outputs=model(images)\n",
        "  loss=F.cross_entropy(outputs,labels)\n",
        "  print(\"Loss:\",loss.item())\n",
        "  break\n",
        "\n",
        "print(\"outputs.shape:\",outputs.shape)\n",
        "print(\"Sample outputs:\\n\",outputs[:2].data)"
      ],
      "metadata": {
        "id": "RTPOFCVVs4ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "mUfeqNMCuD8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "  if torch.cuda.is_available():\n",
        "    return torch.device(\"cuda\")\n",
        "\n",
        "  else:\n",
        "    return torch.device(\"cpu\")\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "pJ6gVVh0RxIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=get_default_device()\n",
        "device"
      ],
      "metadata": {
        "id": "DZnSkcV1TfVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_device(data,device):\n",
        "  \"\"\"move tensors to chosen device\"\"\"\n",
        "  if isinstance(data,(list,tuple)):\n",
        "    return[to_device(x,device) for x in data]\n",
        "  \n",
        "  return data.to(device,non_blocking=True)"
      ],
      "metadata": {
        "id": "zV9y3Gt0TlDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images,labels in train_loader:\n",
        "  print(images.shape)\n",
        "  images=to_device(images,device)\n",
        "  print(images.device)\n",
        "  break"
      ],
      "metadata": {
        "id": "TeEMkBId1GJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeviceDataLoader():\n",
        "  #wrap a dataloader to move data to a device\n",
        "  def __init__(self,dl,device):\n",
        "    self.dl=dl\n",
        "    self.device=device\n",
        "\n",
        "  def __iter__(self):\n",
        "    #yield a batch of data moving it to device\n",
        "    for b in self.dl:\n",
        "      yield to_device(b,self.device)\n",
        "\n",
        "  def __len__(self):\n",
        "    #number of batches\n",
        "    return len(self.dl)\n",
        "    "
      ],
      "metadata": {
        "id": "oTxVAAMK1f1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#example for use of yield\n",
        "def some_numbers():\n",
        "  yield 5\n",
        "  yield 10\n",
        "  yield 15\n",
        "\n",
        "for value in some_numbers():\n",
        "  print(value)"
      ],
      "metadata": {
        "id": "UPu3SmTNXsPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=DeviceDataLoader(train_loader,device)\n",
        "val_loader=DeviceDataLoader(val_loader,device)"
      ],
      "metadata": {
        "id": "lz0hbEckYC6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for xb,yb in val_loader:\n",
        "  print(\"xb.device:\",xb.device)\n",
        "  print(\"yb:\",yb)\n",
        "  break"
      ],
      "metadata": {
        "id": "ftHyw5l7YTP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader):\n",
        "    \"\"\"Evaluate the model's performance on the validation set\"\"\"\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    \"\"\"Train the model using gradient descent\"\"\"\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "metadata": {
        "id": "tLKMvHGDYibA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model on GPU\n",
        "model=MnistModel(input_size,hidden_size=hidden_size,out_size=num_classes)\n",
        "to_device(model,device)"
      ],
      "metadata": {
        "id": "gKxJV334kAHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "history"
      ],
      "metadata": {
        "id": "qqBPkE0Rn_bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history+=fit(5,0.1,model,train_loader,val_loader)"
      ],
      "metadata": {
        "id": "VVK3h4eoo76w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses=[x[\"val_loss\"] for x in history]\n",
        "plt.plot(losses,\"-x\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"Loss vs.No.of epochs\");\n"
      ],
      "metadata": {
        "id": "ez0SUHnH5Fxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies=[x[\"val_acc\"] for x in history]\n",
        "plt.plot(accuracies,\"-x\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title(\"Accuracy vs.No.of epochs\");"
      ],
      "metadata": {
        "id": "qbUwShKj-a70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define test dataset\n",
        "test_dataset=MNIST(root=\"data/\",train=False,transform=ToTensor())\n"
      ],
      "metadata": {
        "id": "oV-anYol_gIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(img,model):\n",
        "  xb=to_device(img.unsqueeze(0),device)\n",
        "  yb=model(xb)\n",
        "  _,preds=torch.max(yb,dim=1)\n",
        "  return preds[0].item()\n"
      ],
      "metadata": {
        "id": "Uv-F156nA9HB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img,label=test_dataset[0]\n",
        "plt.imshow(img[0],cmap=\"gray\")\n",
        "print(\"label:\",label,\"predicted:\",predict_image(img,model))\n"
      ],
      "metadata": {
        "id": "Hq_E4Xv0EpBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader=DeviceDataLoader(DataLoader(test_dataset,batch_size=256),device)\n",
        "result=evaluate(model,test_loader)\n",
        "result"
      ],
      "metadata": {
        "id": "MiC4Vfl2FGlv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}